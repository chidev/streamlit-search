{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = 'YOUR API KEY HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en (\"English (auto-generated)\")[TRANSLATABLE]\n"
     ]
    }
   ],
   "source": [
    "def get_transcript(youtube_url):\n",
    "    video_id = youtube_url.split(\"v=\")[-1]\n",
    "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "\n",
    "    # Try fetching the manual transcript\n",
    "    try:\n",
    "        transcript = transcript_list.find_manually_created_transcript()\n",
    "        language_code = transcript.language_code  # Save the detected language\n",
    "    except:\n",
    "        # If no manual transcript is found, try fetching an auto-generated transcript in a supported language\n",
    "        try:\n",
    "            generated_transcripts = [trans for trans in transcript_list if trans.is_generated]\n",
    "            transcript = generated_transcripts[0]\n",
    "            language_code = transcript.language_code  # Save the detected language\n",
    "        except:\n",
    "            # If no auto-generated transcript is found, raise an exception\n",
    "            raise Exception(\"No suitable transcript found.\")\n",
    "        \n",
    "    print(transcript)\n",
    "\n",
    "    full_transcript = \" \".join([part['text'] for part in transcript.fetch()])\n",
    "    return full_transcript, language_code  # Return both the transcript and detected language\n",
    "\n",
    "# Load the txt file\n",
    "# txt_path = 'stateoftheunion.txt'\n",
    "# with open(txt_path, 'r') as f:\n",
    "#   txt = f.read()\n",
    "\n",
    "# txt = get_transcript(\"https://www.youtube.com/watch?v=qyomWr_C_jA\")[0]\n",
    "txt = get_transcript(\"https://www.youtube.com/watch?v=mGMDyPTR7QU\")[0]\n",
    "\n",
    "with open('transcript.txt', 'w') as f:\n",
    "    f.write(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get segments from txt by splitting on .\n",
    "segments =  txt.split('.')\n",
    "# Put the . back in\n",
    "segments = [segment + '.' for segment in segments]\n",
    "# Further split by comma\n",
    "segments = [segment.split(',') for segment in segments]\n",
    "# Flatten\n",
    "segments = [item for sublist in segments for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences(segments, MIN_WORDS, MAX_WORDS):\n",
    "\n",
    "  # Combine the non-sentences together\n",
    "  sentences = []\n",
    "\n",
    "  is_new_sentence = True\n",
    "  sentence_length = 0\n",
    "  sentence_num = 0\n",
    "  sentence_segments = []\n",
    "\n",
    "  for i in range(len(segments)):\n",
    "    if is_new_sentence == True:\n",
    "      is_new_sentence = False\n",
    "    # Append the segment\n",
    "    sentence_segments.append(segments[i])\n",
    "    segment_words = segments[i].split(' ')\n",
    "    sentence_length += len(segment_words)\n",
    "    \n",
    "    # If exceed MAX_WORDS, then stop at the end of the segment\n",
    "    # Only consider it a sentence if the length is at least MIN_WORDS\n",
    "    if (sentence_length >= MIN_WORDS and segments[i][-1] == '.') or sentence_length >= MAX_WORDS:\n",
    "      sentence = ' '.join(sentence_segments)\n",
    "      sentences.append({\n",
    "        'sentence_num': sentence_num,\n",
    "        'text': sentence,\n",
    "        'sentence_length': sentence_length\n",
    "      })\n",
    "      # Reset\n",
    "      is_new_sentence = True\n",
    "      sentence_length = 0\n",
    "      sentence_segments = []\n",
    "      sentence_num += 1\n",
    "\n",
    "  return sentences\n",
    "\n",
    "def create_chunks(sentences, CHUNK_LENGTH, STRIDE):\n",
    "\n",
    "  sentences_df = pd.DataFrame(sentences)\n",
    "  \n",
    "  chunks = []\n",
    "  for i in range(0, len(sentences_df), (CHUNK_LENGTH - STRIDE)):\n",
    "    chunk = sentences_df.iloc[i:i+CHUNK_LENGTH]\n",
    "    chunk_text = ' '.join(chunk['text'].tolist())\n",
    "    \n",
    "    chunks.append({\n",
    "      'start_sentence_num': chunk['sentence_num'].iloc[0],\n",
    "      'end_sentence_num': chunk['sentence_num'].iloc[-1],\n",
    "      'text': chunk_text,\n",
    "      'num_words': len(chunk_text.split(' '))\n",
    "    })\n",
    "    \n",
    "  chunks_df = pd.DataFrame(chunks)\n",
    "  return chunks_df.to_dict('records')\n",
    "\n",
    "def parse_title_summary_results(results):\n",
    "  print(results)\n",
    "  out = []\n",
    "  for e in results:\n",
    "    # split on \\n, remove remaining \\n, then map over each element\n",
    "    processed = list(map(lambda x: x.replace('\\n', '').replace('**', '').strip(), e.split('\\n')))\n",
    "    # trim\n",
    "    \n",
    "    print(processed)\n",
    "    \n",
    "    # get first line spread the rest\n",
    "    line1 = processed[0]\n",
    "    \n",
    "    steps = processed[1:]\n",
    "    \n",
    "    # remove empty lines\n",
    "    steps = list(filter(lambda x: x != '', steps))\n",
    "    \n",
    "    # create array of objects with step and description, split on |, remove leading/trailing whitespace\n",
    "    steps = list(map(lambda x: {'step': x.split('|')[0].strip(), 'description': x.split('|')[1].strip()}, steps))\n",
    "    \n",
    "    print\n",
    "    \n",
    "    if '|' in line1:\n",
    "      processed = {'title': line1.split('|')[0],\n",
    "                    'summary': line1.split('|')[1][1:],\n",
    "                    'steps': steps\n",
    "                    }\n",
    "    else:\n",
    "      processed = {'title': '',\n",
    "                    'summary': e\n",
    "                    }\n",
    "    out.append(processed)\n",
    "  return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = create_sentences(segments, MIN_WORDS=10, MAX_WORDS=40)\n",
    "chunks = create_chunks(sentences, CHUNK_LENGTH=5, STRIDE=1)\n",
    "chunks_text = [chunk['text'] for chunk in chunks]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Getting Chunk Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_stage_1(chunks_text):\n",
    "  \n",
    "  print(f'Start time: {datetime.now()}')\n",
    "\n",
    "  # Prompt to get title and summary for each chunk\n",
    "  # map_prompt_template = \"\"\"Firstly, give the following text an informative title and choose a topical emoji to place at the beginning. Then, on a new line, write a 75-100 word summary. Then, on a new line, list the 3 most relevant topics separated by commas. Do not start the topics line with a label or heading. Here is the text:\n",
    "  map_prompt_template = \"\"\"On the first line I want an informative title and summary.\n",
    "  {text}\n",
    "  \n",
    "  If you have any insights or action steps, please list them below the summary.\n",
    "  \n",
    "  Return your answer in the following format:\n",
    "  Title | Summary...\n",
    "  * Step | What to do...\n",
    "  * Step | What to do...\n",
    "  * Step | What to do...\n",
    "  etc...\n",
    "  \n",
    "  e.g. \n",
    "  Why Artificial Intelligence is Good | AI can make humans more productive by automating many repetitive processes.\n",
    "  * How to train AI | Collect data, train the model, test model.\n",
    "  * How to sell AI | Find customers, Pitch to customers, Close the deal.\n",
    "\n",
    "  TITLE AND CONCISE SUMMARY:\"\"\"\n",
    "\n",
    "  map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "  # Define the LLMs\n",
    "  map_llm = ChatOpenAI(temperature=0, model_name = 'gpt-4o-mini')\n",
    "  map_llm_chain = LLMChain(llm = map_llm, prompt = map_prompt)\n",
    "  map_llm_chain_input = [{'text': t} for t in chunks_text]\n",
    "  # Run the input through the LLM chain (works in parallel)\n",
    "  map_llm_chain_results = map_llm_chain.apply(map_llm_chain_input)\n",
    "\n",
    "  stage_1_outputs = parse_title_summary_results([e['text'] for e in map_llm_chain_results])\n",
    "  \n",
    "  # save stage 1 outputs to file\n",
    "  with open('stage_1_outputs.json', 'w') as f:\n",
    "    json.dump(map_llm_chain_results, f)\n",
    "\n",
    "  print(f'Stage 1 done time {datetime.now()}')\n",
    "\n",
    "  return {\n",
    "    'stage_1_outputs': stage_1_outputs\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2024-08-18 06:51:35.670602\n",
      "[\"Building a Successful Mobile App with ChatGPT | In the past year, a 23-year-old entrepreneur generated $5 million in revenue by leveraging ChatGPT to create a mobile app called RZ GPT, which helps users craft better responses on dating apps. By identifying a clear use case and utilizing social media marketing effectively, the app achieved rapid growth and significant monthly revenue. The entrepreneur emphasizes the importance of problem-solving, influencer outreach, and the potential of AI tools in app development.\\n\\n* Identify a Clear Use Case | Focus on solving a specific problem that resonates with your target audience.\\n* Leverage AI Tools | Use AI platforms like ChatGPT to assist in coding and app development, even if you're not a technical expert.\\n* Utilize Influencer Marketing | Reach out to relevant influencers for promotions, focusing on engagement and views rather than just follower count.\\n* Test Different Messaging Strategies | Experiment with various outreach messages to find what resonates best with potential partners or customers.\\n* Reinvent and Scale | Continuously reinvest profits into new projects and improvements to maintain growth and explore new opportunities.\", 'Building Successful Apps with Minimal Technical Knowledge | The journey of creating successful mobile applications can be simplified by leveraging new technologies and understanding market needs. The discussion highlights how one entrepreneur built multiple apps, including Riz GPT and Umax, using AI tools like ChatGPT and GPT Vision, emphasizing the importance of identifying clear problems to solve and effective influencer outreach for marketing.\\n\\n* Identify a Market Need | Research trending topics and identify specific problems that can be solved with a new app.\\n* Leverage AI Tools | Use AI technologies like ChatGPT and GPT Vision to assist in app development and problem-solving.\\n* Build a Minimal Viable Product (MVP) | Focus on creating a simple version of the app that addresses the core problem before scaling.\\n* Engage Influencers for Marketing | Reach out to relevant influencers in your niche to promote your app, using both mass outreach and personalized approaches.\\n* Test and Iterate | Continuously gather feedback from users and make improvements to the app based on their needs and preferences.\\n* Stay Agile and Adaptable | Be willing to pivot your strategy based on market changes and competition, while maintaining a focus on execution.', 'Building Successful Apps Through Market Insight and Influencer Partnerships | The discussion highlights the journey of creating two successful apps, Riz GPT and Umax, emphasizing the importance of market awareness, influencer collaboration, and rapid execution in app development. The speaker shares insights on identifying trends, leveraging new technologies, and the significance of user-centric design in achieving substantial revenue growth.\\n\\n* Identify Market Trends | Research emerging trends and technologies to find gaps in the market that can be addressed with new apps.\\n* Leverage Influencer Partnerships | Collaborate with influencers who resonate with your target audience to enhance visibility and credibility.\\n* Focus on User Experience | Design apps with a simple, intuitive user interface that addresses specific user needs and provides actionable insights.\\n* Build Quickly and Iterate | Develop a minimum viable product (MVP) rapidly, gather user feedback, and make improvements based on real-world usage.\\n* Establish a Revenue Model Early | Consider various monetization strategies from the outset to ensure financial sustainability as the app grows.', 'Building a Self-Actualization Ecosystem | Blake Anderson discusses his journey from developing consumer apps to launching Apex, a self-improvement platform aimed at helping individuals achieve their fullest potential. He emphasizes the importance of passion-driven work, the impact of nature on mental clarity, and the need for a balanced approach to self-improvement, contrasting it with the often superficial narratives prevalent on social media.\\n\\n* Step | Identify your passion: Reflect on what truly excites you and aligns with your values to ensure fulfillment in your work.\\n* Step | Build a supportive community: Surround yourself with like-minded individuals who share your vision and can contribute to your goals.\\n* Step | Create valuable content: Focus on producing content that genuinely helps others, rather than chasing trends or maximizing profit.\\n* Step | Embrace nature: Incorporate time in nature into your routine to enhance mental clarity and foster creativity.\\n* Step | Iterate and adapt: Be open to feedback and willing to adjust your strategies based on what resonates with your audience and community.', 'Apex: A New Opportunity for Content Creators | Apex is a new company focused on self-improvement and self-actualization, inviting ambitious individuals interested in content creation to follow their journey on Instagram. Although the account currently has no content, it promises exciting developments soon. \\n\\n* Follow Apex on Instagram | Check out their account @apex.pro and stay updated on upcoming content.\\n* Connect with Blake on Twitter | Follow Blake for insights and inspiration related to self-improvement and content creation.\\n* Engage with the community | If you align with the values of self-actualization and ambition, consider reaching out to like-minded individuals and explore collaboration opportunities.']\n",
      "['Building a Successful Mobile App with ChatGPT | In the past year, a 23-year-old entrepreneur generated $5 million in revenue by leveraging ChatGPT to create a mobile app called RZ GPT, which helps users craft better responses on dating apps. By identifying a clear use case and utilizing social media marketing effectively, the app achieved rapid growth and significant monthly revenue. The entrepreneur emphasizes the importance of problem-solving, influencer outreach, and the potential of AI tools in app development.', '', '* Identify a Clear Use Case | Focus on solving a specific problem that resonates with your target audience.', \"* Leverage AI Tools | Use AI platforms like ChatGPT to assist in coding and app development, even if you're not a technical expert.\", '* Utilize Influencer Marketing | Reach out to relevant influencers for promotions, focusing on engagement and views rather than just follower count.', '* Test Different Messaging Strategies | Experiment with various outreach messages to find what resonates best with potential partners or customers.', '* Reinvent and Scale | Continuously reinvest profits into new projects and improvements to maintain growth and explore new opportunities.']\n",
      "['Building Successful Apps with Minimal Technical Knowledge | The journey of creating successful mobile applications can be simplified by leveraging new technologies and understanding market needs. The discussion highlights how one entrepreneur built multiple apps, including Riz GPT and Umax, using AI tools like ChatGPT and GPT Vision, emphasizing the importance of identifying clear problems to solve and effective influencer outreach for marketing.', '', '* Identify a Market Need | Research trending topics and identify specific problems that can be solved with a new app.', '* Leverage AI Tools | Use AI technologies like ChatGPT and GPT Vision to assist in app development and problem-solving.', '* Build a Minimal Viable Product (MVP) | Focus on creating a simple version of the app that addresses the core problem before scaling.', '* Engage Influencers for Marketing | Reach out to relevant influencers in your niche to promote your app, using both mass outreach and personalized approaches.', '* Test and Iterate | Continuously gather feedback from users and make improvements to the app based on their needs and preferences.', '* Stay Agile and Adaptable | Be willing to pivot your strategy based on market changes and competition, while maintaining a focus on execution.']\n",
      "['Building Successful Apps Through Market Insight and Influencer Partnerships | The discussion highlights the journey of creating two successful apps, Riz GPT and Umax, emphasizing the importance of market awareness, influencer collaboration, and rapid execution in app development. The speaker shares insights on identifying trends, leveraging new technologies, and the significance of user-centric design in achieving substantial revenue growth.', '', '* Identify Market Trends | Research emerging trends and technologies to find gaps in the market that can be addressed with new apps.', '* Leverage Influencer Partnerships | Collaborate with influencers who resonate with your target audience to enhance visibility and credibility.', '* Focus on User Experience | Design apps with a simple, intuitive user interface that addresses specific user needs and provides actionable insights.', '* Build Quickly and Iterate | Develop a minimum viable product (MVP) rapidly, gather user feedback, and make improvements based on real-world usage.', '* Establish a Revenue Model Early | Consider various monetization strategies from the outset to ensure financial sustainability as the app grows.']\n",
      "['Building a Self-Actualization Ecosystem | Blake Anderson discusses his journey from developing consumer apps to launching Apex, a self-improvement platform aimed at helping individuals achieve their fullest potential. He emphasizes the importance of passion-driven work, the impact of nature on mental clarity, and the need for a balanced approach to self-improvement, contrasting it with the often superficial narratives prevalent on social media.', '', '* Step | Identify your passion: Reflect on what truly excites you and aligns with your values to ensure fulfillment in your work.', '* Step | Build a supportive community: Surround yourself with like-minded individuals who share your vision and can contribute to your goals.', '* Step | Create valuable content: Focus on producing content that genuinely helps others, rather than chasing trends or maximizing profit.', '* Step | Embrace nature: Incorporate time in nature into your routine to enhance mental clarity and foster creativity.', '* Step | Iterate and adapt: Be open to feedback and willing to adjust your strategies based on what resonates with your audience and community.']\n",
      "['Apex: A New Opportunity for Content Creators | Apex is a new company focused on self-improvement and self-actualization, inviting ambitious individuals interested in content creation to follow their journey on Instagram. Although the account currently has no content, it promises exciting developments soon.', '', '* Follow Apex on Instagram | Check out their account @apex.pro and stay updated on upcoming content.', '* Connect with Blake on Twitter | Follow Blake for insights and inspiration related to self-improvement and content creation.', '* Engage with the community | If you align with the values of self-actualization and ambition, consider reaching out to like-minded individuals and explore collaboration opportunities.']\n",
      "Stage 1 done time 2024-08-18 06:51:50.712862\n"
     ]
    }
   ],
   "source": [
    "# Run Stage 1 Summarizing\n",
    "stage_1_outputs = summarize_stage_1(chunks_text)['stage_1_outputs']\n",
    "# Split the titles and summaries\n",
    "stage_1_summaries = [e['summary'] for e in stage_1_outputs]\n",
    "stage_1_titles = [e['title'] for e in stage_1_outputs]\n",
    "num_1_chunks = len(stage_1_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenAI to embed the summaries and titles. Size of _embeds: (num_chunks x 1536)\n",
    "openai_embed = OpenAIEmbeddings()\n",
    "\n",
    "summary_embeds = np.array(openai_embed.embed_documents(stage_1_summaries))\n",
    "title_embeds = np.array(openai_embed.embed_documents(stage_1_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similarity matrix between the embeddings of the chunk summaries\n",
    "summary_similarity_matrix = np.zeros((num_1_chunks, num_1_chunks))\n",
    "summary_similarity_matrix[:] = np.nan\n",
    "\n",
    "for row in range(num_1_chunks):\n",
    "  for col in range(row, num_1_chunks):\n",
    "    # Calculate cosine similarity between the two vectors\n",
    "    similarity = 1- cosine(summary_embeds[row], summary_embeds[col])\n",
    "    summary_similarity_matrix[row, col] = similarity\n",
    "    summary_similarity_matrix[col, row] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x30d58d510>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw a heatmap with the summary_similarity_matrix\n",
    "plt.figure()\n",
    "# Color scheme blues\n",
    "plt.imshow(summary_similarity_matrix, cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the community detection algorithm\n",
    "\n",
    "def get_topics(title_similarity, num_topics = 16, bonus_constant = 0.25, min_size = 3):\n",
    "\n",
    "  proximity_bonus_arr = np.zeros_like(title_similarity)\n",
    "  for row in range(proximity_bonus_arr.shape[0]):\n",
    "    for col in range(proximity_bonus_arr.shape[1]):\n",
    "      if row == col:\n",
    "        proximity_bonus_arr[row, col] = 0\n",
    "      else:\n",
    "        proximity_bonus_arr[row, col] = 1/(abs(row-col)) * bonus_constant\n",
    "        \n",
    "  title_similarity += proximity_bonus_arr\n",
    "\n",
    "  title_nx_graph = nx.from_numpy_array(title_similarity)\n",
    "\n",
    "  desired_num_topics = num_topics\n",
    "  # Store the accepted partitionings\n",
    "  topics_title_accepted = []\n",
    "\n",
    "  resolution = 0.85\n",
    "  resolution_step = 0.01\n",
    "  iterations = 40\n",
    "\n",
    "  # Find the resolution that gives the desired number of topics\n",
    "  topics_title = []\n",
    "  while len(topics_title) not in [desired_num_topics, desired_num_topics + 1, desired_num_topics + 2]:\n",
    "    topics_title = community.louvain_communities(title_nx_graph, weight = 'weight', resolution = resolution)\n",
    "    resolution += resolution_step\n",
    "  topic_sizes = [len(c) for c in topics_title]\n",
    "  sizes_sd = np.std(topic_sizes)\n",
    "  modularity = community.modularity(title_nx_graph, topics_title, weight = 'weight', resolution = resolution)\n",
    "\n",
    "  lowest_sd_iteration = 0\n",
    "  # Set lowest sd to inf\n",
    "  lowest_sd = float('inf')\n",
    "\n",
    "  for i in range(iterations):\n",
    "    topics_title = community.louvain_communities(title_nx_graph, weight = 'weight', resolution = resolution)\n",
    "    modularity = community.modularity(title_nx_graph, topics_title, weight = 'weight', resolution = resolution)\n",
    "    \n",
    "    # Check SD\n",
    "    topic_sizes = [len(c) for c in topics_title]\n",
    "    sizes_sd = np.std(topic_sizes)\n",
    "    \n",
    "    topics_title_accepted.append(topics_title)\n",
    "    \n",
    "    if sizes_sd < lowest_sd and min(topic_sizes) >= min_size:\n",
    "      lowest_sd_iteration = i\n",
    "      lowest_sd = sizes_sd\n",
    "      \n",
    "  # Set the chosen partitioning to be the one with highest modularity\n",
    "  topics_title = topics_title_accepted[lowest_sd_iteration]\n",
    "  print(f'Best SD: {lowest_sd}, Best iteration: {lowest_sd_iteration}')\n",
    "  \n",
    "  topic_id_means = [sum(e)/len(e) for e in topics_title]\n",
    "  # Arrange title_topics in order of topic_id_means\n",
    "  topics_title = [list(c) for _, c in sorted(zip(topic_id_means, topics_title), key = lambda pair: pair[0])]\n",
    "  # Create an array denoting which topic each chunk belongs to\n",
    "  chunk_topics = [None] * title_similarity.shape[0]\n",
    "  for i, c in enumerate(topics_title):\n",
    "    for j in c:\n",
    "      chunk_topics[j] = i\n",
    "            \n",
    "  return {\n",
    "    'chunk_topics': chunk_topics,\n",
    "    'topics': topics_title\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SD: inf, Best iteration: 0\n"
     ]
    }
   ],
   "source": [
    "# Set num_topics to be 1/4 of the number of chunks, or 8, which ever is smaller\n",
    "num_topics = min(int(num_1_chunks / 4), 8)\n",
    "topics_out = get_topics(summary_similarity_matrix, num_topics = num_topics, bonus_constant = 0.2)\n",
    "chunk_topics = topics_out['chunk_topics']\n",
    "topics = topics_out['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a heatmap of this array\n",
    "plt.figure(figsize = (10, 4))\n",
    "plt.imshow(np.array(chunk_topics).reshape(1, -1), cmap = 'tab20')\n",
    "# Draw vertical black lines for every 1 of the x-axis \n",
    "for i in range(1, len(chunk_topics)):\n",
    "  plt.axvline(x = i - 0.5, color = 'black', linewidth = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_stage_2(stage_1_outputs, topics, summary_num_words = 250):\n",
    "  print(f'Stage 2 start time {datetime.now()}')\n",
    "  \n",
    "  # Prompt that passes in all the titles of a topic, and asks for an overall title of the topic\n",
    "  title_prompt_template = \"\"\"Write an informative title that summarizes each of the following groups of titles. Make sure that the titles capture as much information as possible, \n",
    "  and are different from each other:\n",
    "  {text}\n",
    "  \n",
    "  Return your answer in a numbered list, with new line separating each title: \n",
    "  1. Title 1\n",
    "  2. Title 2\n",
    "  3. Title 3\n",
    "\n",
    "  TITLES:\n",
    "  \"\"\"\n",
    "\n",
    "  map_prompt_template = \"\"\"Write a 75-100 word summary of the following text, refraining from starting sentences with \"The text is about...\" or \"The text discusses...\". Finish your answer:\n",
    "    {text}\n",
    "\n",
    "    CONCISE SUMMARY:\"\"\"\n",
    "\n",
    "  combine_prompt_template = 'Write a ' + str(summary_num_words) + \"\"\"-word summary of the following, removing irrelevant information. Finish your answer:\n",
    "  {text}\n",
    "  \"\"\" + str(summary_num_words) + \"\"\"-WORD SUMMARY:\"\"\"\n",
    "\n",
    "  title_prompt = PromptTemplate(template=title_prompt_template, input_variables=[\"text\"])\n",
    "  map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "  combine_prompt = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "  topics_data = []\n",
    "  for c in topics:\n",
    "    topic_data = {\n",
    "      'summaries': [stage_1_outputs[chunk_id]['summary'] for chunk_id in c],\n",
    "      'titles': [stage_1_outputs[chunk_id]['title'] for chunk_id in c]\n",
    "    }\n",
    "    topic_data['summaries_concat'] = ' '.join(topic_data['summaries'])\n",
    "    topic_data['titles_concat'] = ', '.join(topic_data['titles'])\n",
    "    topics_data.append(topic_data)\n",
    "    \n",
    "  # Get a list of each community's summaries (concatenated)\n",
    "  topics_summary_concat = [c['summaries_concat'] for c in topics_data]\n",
    "  topics_titles_concat = [c['titles_concat'] for c in topics_data]\n",
    "\n",
    "  # Concat into one long string to do the topic title creation\n",
    "  topics_titles_concat_all = ''''''\n",
    "  for i, c in enumerate(topics_titles_concat):\n",
    "    topics_titles_concat_all += f'''{i+1}. {c}\n",
    "    '''\n",
    "  \n",
    "  # print('topics_titles_concat_all', topics_titles_concat_all)\n",
    "\n",
    "  title_llm = ChatOpenAI(temperature=0, model_name = 'gpt-4o-mini')\n",
    "  title_llm_chain = LLMChain(llm = title_llm, prompt = title_prompt)\n",
    "  title_llm_chain_input = [{'text': topics_titles_concat_all}]\n",
    "  title_llm_chain_results = title_llm_chain.apply(title_llm_chain_input)\n",
    "  \n",
    "  \n",
    "  # Split by new line\n",
    "  titles = title_llm_chain_results[0]['text'].split('\\n')\n",
    "  # Remove any empty titles\n",
    "  titles = [t for t in titles if t != '']\n",
    "  # Remove spaces at start or end of each title\n",
    "  titles = [t.strip() for t in titles]\n",
    "\n",
    "  map_llm = ChatOpenAI(temperature=0, model_name = 'gpt-4o-mini')\n",
    "  reduce_llm = ChatOpenAI(temperature=0, model_name = 'gpt-4o-mini')\n",
    "\n",
    "  # Run the map-reduce chain\n",
    "  docs = [Document(page_content=t) for t in topics_summary_concat]\n",
    "  chain = load_summarize_chain(chain_type=\"map_reduce\", map_prompt = map_prompt, combine_prompt = combine_prompt, return_intermediate_steps = True,\n",
    "                              llm = map_llm, reduce_llm = reduce_llm)\n",
    "\n",
    "  output = chain({\"input_documents\": docs}, return_only_outputs = True)\n",
    "  summaries = output['intermediate_steps']\n",
    "  stage_2_outputs = [{'title': t, 'summary': s} for t, s in zip(titles, summaries)]\n",
    "  final_summary = output['output_text']\n",
    "\n",
    "  # Return: stage_1_outputs (title and summary), stage_2_outputs (title and summary), final_summary, chunk_allocations\n",
    "  out = {\n",
    "    'stage_2_outputs': stage_2_outputs,\n",
    "    'final_summary': final_summary\n",
    "  }\n",
    "  print(f'Stage 2 done time {datetime.now()}')\n",
    "  \n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 start time 2024-08-18 06:51:51.444177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 done time 2024-08-18 06:51:59.573691\n"
     ]
    }
   ],
   "source": [
    "# Query GPT-3 to get a summarized title for each topic_data\n",
    "out = summarize_stage_2(stage_1_outputs, topics, summary_num_words = 250)\n",
    "stage_2_outputs = out['stage_2_outputs']\n",
    "stage_2_titles = [e['title'] for e in stage_2_outputs]\n",
    "stage_2_summaries = [e['summary'] for e in stage_2_outputs]\n",
    "final_summary = out['final_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '1. Strategies for Developing Successful Mobile Applications: Leveraging ChatGPT, Market Insights, and Influencer Collaborations',\n",
       "  'summary': 'A 23-year-old entrepreneur generated $5 million in revenue within a year by developing RZ GPT, a mobile app that enhances dating app responses using ChatGPT. By focusing on a specific problem and employing effective social media marketing, the app experienced rapid growth. The entrepreneur highlights the significance of problem-solving, influencer outreach, and leveraging AI tools in app development. Additionally, insights on market awareness, user-centric design, and trend identification are shared, showcasing how these elements contribute to the success of multiple apps, including Riz GPT and Umax.'},\n",
       " {'title': '2. Creating a Self-Actualization Ecosystem and Exploring New Opportunities for Content Creators with Apex',\n",
       "  'summary': 'Blake Anderson shares his transition from creating consumer apps to founding Apex, a self-improvement platform designed to help individuals reach their full potential. He highlights the significance of pursuing passion-driven work, the benefits of nature for mental clarity, and the necessity of a balanced self-improvement approach, in contrast to superficial social media narratives. Apex aims to engage ambitious content creators and invites them to follow its Instagram account, which, despite lacking content at the moment, promises exciting updates in the near future.'}]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_2_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A 23-year-old entrepreneur generated $5 million in revenue within a year by developing RZ GPT, a mobile app that enhances dating app responses using ChatGPT. The app's rapid growth can be attributed to effective social media marketing and a focus on solving a specific problem. The entrepreneur emphasizes the importance of problem-solving, influencer outreach, and leveraging AI tools in app development. Insights on market awareness, user-centric design, and trend identification are also shared, illustrating how these factors contribute to the success of various apps, including Riz GPT and Umax.\\n\\nBlake Anderson, transitioning from consumer apps to founding Apex, a self-improvement platform, underscores the importance of pursuing passion-driven work and the benefits of nature for mental clarity. He advocates for a balanced approach to self-improvement, contrasting it with superficial social media narratives. Apex aims to engage ambitious content creators and encourages them to follow its Instagram account, which, while currently lacking content, promises exciting updates in the near future.\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save stage_1_outputs, stage_2_outputs, final_summary, chunk_topics, topics to a json file\n",
    "output = {\n",
    "    'stage_1_outputs': stage_1_outputs,\n",
    "    'stage_2_outputs': stage_2_outputs,\n",
    "    'final_summary': final_summary,\n",
    "}\n",
    "\n",
    "with open('output.json', 'w') as f:\n",
    "    json.dump(output, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fastapi_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d228f8d1b134e326a52396b2016d42a4e7c84199cf5eb27412c1836171e03131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
